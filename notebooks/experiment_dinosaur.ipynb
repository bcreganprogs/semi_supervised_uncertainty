{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "\n",
    "from models.data import JSRTDataModule, CheXpertDataModule\n",
    "from models.mae import ViTAE\n",
    "from models.dinosaur import DINOSAUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = ViTAE.load_from_checkpoint('/vol/bitbucket/bc1623/project/semi_supervised_uncertainty/bash_scripts/lightning_logs/chestxray_mae/chestxray_mae/beznyxtr/checkpoints/epoch=495-step=93744.ckpt',\n",
    "    model_kwargs={\n",
    "        'img_size': 224,\n",
    "        'embed_dim': 768,\n",
    "        'in_chans': 1,\n",
    "        'num_heads': 12,\n",
    "        'depth': 12,\n",
    "        'decoder_embed_dim': 512,\n",
    "        'decoder_depth': 8,\n",
    "        'decoder_num_heads': 16,\n",
    "        'norm_layer': partial(nn.LayerNorm, eps=1e-6),\n",
    "        'mlp_ratio': 4.0,\n",
    "        'patch_size': 16,\n",
    "        'norm_pix_loss': False,\n",
    "        'mask_ratio': 0.00,\n",
    "        #'dropout': 0.00,\n",
    "    },\n",
    "    learning_rate=1e-4,\n",
    "    map_location=torch.device('cpu'),\n",
    "    )\n",
    "\n",
    "saved_model2 = ViTAE.load_from_checkpoint('/vol/bitbucket/bc1623/project/semi_supervised_uncertainty/bash_scripts/lightning_logs/chestxray_mae/chestxray_mae/beznyxtr/checkpoints/epoch=495-step=93744.ckpt',\n",
    "    model_kwargs={\n",
    "        'img_size': 224,\n",
    "        'embed_dim': 768,\n",
    "        'in_chans': 1,\n",
    "        'num_heads': 12,\n",
    "        'depth': 12,\n",
    "        'decoder_embed_dim': 512,\n",
    "        'decoder_depth': 8,\n",
    "        'decoder_num_heads': 16,\n",
    "        'norm_layer': partial(nn.LayerNorm, eps=1e-6),\n",
    "        'mlp_ratio': 4.0,\n",
    "        'patch_size': 16,\n",
    "        'norm_pix_loss': False,\n",
    "        'mask_ratio': 0.00,\n",
    "        #'dropout': 0.00,\n",
    "    },\n",
    "    learning_rate=1e-4,\n",
    "    map_location=torch.device('cpu'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchmetrics.functional import dice\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
    "from pytorch_lightning import LightningModule\n",
    "import wandb\n",
    "\n",
    "from utils.utils import SoftPositionEmbed, spatial_broadcast, unstack_and_split\n",
    "from models.slot_attention import ProbabalisticSlotAttention, FixedSlotAttention, SlotAttention\n",
    "from models.decoders import SlotSpecificDecoder, Decoder\n",
    "\n",
    "class DINOSAUR(LightningModule):\n",
    "    def __init__(self, frozen_encoder, trainable_encoder, num_slots, num_iterations, num_classes, slot_dim=128, task='recon', include_seg_loss=False, probabilistic_slots=True, \n",
    "                learning_rate=1e-3, hidden_decoder_dim=2048, temperature=1, lr_warmup=True, log_images=True):\n",
    "        super(DINOSAUR, self).__init__()\n",
    "\n",
    "        self.frozen_encoder = frozen_encoder.model\n",
    "        self.trainable_encoder = trainable_encoder.model\n",
    "        self.encoder_pos_embeddings = SoftPositionEmbed(slot_dim, (14, 14))\n",
    "        if probabilistic_slots:\n",
    "            self.slot_attention = ProbabalisticSlotAttention(num_slots=num_slots, dim=slot_dim, num_iterations=num_iterations, temperature=temperature)\n",
    "        else:\n",
    "            self.slot_attention = SlotAttention(num_slots, slot_dim, num_iterations, temperature=temperature)\n",
    "            #FixedSlotAttention(num_slots=num_slots, dim=slot_dim, num_iterations=num_iterations, temperature=temperature)\n",
    "        \n",
    "        # four-layer mlp\n",
    "        self.mlp_decoder = nn.Sequential(\n",
    "            nn.Linear(slot_dim, hidden_decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_decoder_dim, hidden_decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_decoder_dim, hidden_decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_decoder_dim, 768 + 1) # extra one for alpha masks\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, slot_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(slot_dim, slot_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder_pos_embeddings = SoftPositionEmbed(slot_dim, (14, 14))\n",
    "        self.num_classes = num_classes\n",
    "        self.task = task\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_warmup = lr_warmup\n",
    "        self.embedding_norm = nn.LayerNorm(768)\n",
    "        self.embedding_norm_decoder = nn.LayerNorm(slot_dim)\n",
    "\n",
    "        self.include_seg_loss = include_seg_loss\n",
    "\n",
    "        self.attn = None\n",
    "        self.masks = None\n",
    "        self.recons = None\n",
    "        self.preds = None\n",
    "\n",
    "        for param in self.frozen_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "  \n",
    "        self.mlp_decoder.apply(self.init_weights)\n",
    "        self.mlp.apply(self.init_weights)\n",
    "        self.slot_attention.apply(self.init_weights)\n",
    "\n",
    "        self.test_predmaps = []\n",
    "        self.test_probmaps = []\n",
    "\n",
    "        # for logging\n",
    "        self.log_images = log_images\n",
    "        if log_images:\n",
    "            self.save_hyperparameters(ignore=['encoder'])\n",
    "\n",
    "        self.train_imgs = None\n",
    "        self.train_preds = None\n",
    "        self.val_imgs = None\n",
    "        self.val_preds = None\n",
    "        self.logged_train_images_this_epoch = False\n",
    "        self.logged_val_images_this_epoch = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        with torch.no_grad():\n",
    "            patch_embeddings_frozen, _, _ = self.frozen_encoder.forward_encoder(x, 0.0)\n",
    "            patch_embeddings_frozen = patch_embeddings_frozen[:, 1:, :]     # exclude cls token\n",
    "\n",
    "        # generate patch features from trainable encoder\n",
    "        patch_embeddings_train, _, _ = self.trainable_encoder.forward_encoder(x, 0.0)\n",
    "        patch_embeddings_train = patch_embeddings_train[:, 1:, :]           # exclude cls token\n",
    "\n",
    "        # intermediate mlp between encoder and slot attention\n",
    "        patch_embeddings_train = self.embedding_norm(patch_embeddings_train)\n",
    "        patch_embeddings_train = self.mlp(patch_embeddings_train)                       # shape (batch_size*num_patches, embed_dim)\n",
    "\n",
    "        # apply slot attention to trainable patch features\n",
    "        slots, slot_attn = self.slot_attention(patch_embeddings_train)            # slots: shape (batch_size, num_slots, slot_dim)\n",
    "    \n",
    "        # broadcast each slot to N x N grid (N=14 for 224x224 images)\n",
    "        x = spatial_broadcast(slots, (14, 14))                              # shape (batch_size*num_slots, width_init, height_init, slot_dim)\n",
    "\n",
    "        # decode each slot to a mask\n",
    "        x = self.decoder_pos_embeddings(x)\n",
    "\n",
    "        x = x.view(batch_size, slots.shape[1], 14*14, -1)\n",
    "\n",
    "        x = self.embedding_norm_decoder(x)\n",
    "        x = self.mlp_decoder(x).to(patch_embeddings_train.device)               # shape (batch_size, num_classes, H, W, slot_dim + 1)\n",
    "\n",
    "        decoded = x[:, :, :, :-1]                                               # shape (batch_size, num_slots, num_patches, slot_dim)\n",
    "        masks = x[:, :, :, -1]                                                  # shape (batch_size, num_slots, num_patches)\n",
    "        masks = torch.softmax(masks, dim=1)                                     # softmax over \n",
    "        # log masks\n",
    "        self.masks = masks[0, ...]\n",
    "        masks = masks.unsqueeze(-1)                                             # shape (batch_size, num_slots, num_patches, slot_dim)\n",
    "        recons = torch.sum(decoded * masks, dim=1)\n",
    "\n",
    "        preds = torch.argmax(masks, dim=1)\n",
    "\n",
    "        return patch_embeddings_frozen, recons, masks, preds, slot_attn\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=1e-6)\n",
    "        if not self.lr_warmup:\n",
    "            return optimizer\n",
    "\n",
    "        scheduler = self.warmup_lr_scheduler(optimizer, 10000, 100000, 1e-6, self.learning_rate)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "             \"lr_scheduler\": {\n",
    "                 \"scheduler\": scheduler,\n",
    "            #     #\"monitor\": \"train_loss\",  # metric to monitor\n",
    "                 \"frequency\": 1,  \n",
    "                 \"interval\": \"step\",\n",
    "            #     #\"strict\": True,\n",
    "             },\n",
    "        }\n",
    "    \n",
    "    def warmup_lr_scheduler(self, optimizer, warmup_steps, decay_steps, start_lr, target_lr):\n",
    "        def lr_lambda(current_step):\n",
    "            if current_step < warmup_steps:\n",
    "                return float(current_step) / float(max(1, warmup_steps)) * (target_lr - start_lr) / target_lr + start_lr / target_lr\n",
    "            else:\n",
    "                return 0.5 ** ((current_step - warmup_steps) / decay_steps)\n",
    "        return LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    def process_batch(self, batch, batch_idx):\n",
    "        #x, y = batch['image'], batch['labelmap']\n",
    "        x = batch['image']\n",
    "        # generate patch features from frozen encoder\n",
    "        targets, recons, masks, preds, attn = self(x)\n",
    "\n",
    "        # log masks and attn\n",
    "        self.attn = attn[0, ...]\n",
    "        self.recons = recons[0, ...]\n",
    "        self.preds = preds[0, ...]\n",
    "\n",
    "        # calculate loss\n",
    "        loss = torch.cdist(targets, recons, p=2).mean()\n",
    "        dsc = 1#dice(preds, y.squeeze(), average='macro', num_classes=self.num_classes, ignore_index=0)\n",
    "        \n",
    "        return loss, dsc, preds, x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, dsc, preds, imgs = self.process_batch(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_dice\", dsc, prog_bar=True)\n",
    "\n",
    "        if self.train_imgs is None:\n",
    "            self.train_imgs = imgs[:5].cpu()\n",
    "            self.train_preds = preds[:5].cpu()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, dsc, preds, imgs = self.process_batch(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_dice\", dsc, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        if self.val_imgs is None:\n",
    "            self.val_imgs = imgs[:5].cpu()\n",
    "            self.val_preds = preds[:5].cpu()\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.test_probmaps = []\n",
    "        self.test_predmaps = []\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, dsc, probs, preds = self.process_batch(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_dice\", dsc)\n",
    "        self.test_probmaps.append(probs)\n",
    "        self.test_predmaps.append(preds)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.log_images:\n",
    "            if not self.logged_train_images_this_epoch and self.train_imgs is not None:\n",
    "                self._log_train_images(self.train_imgs, self.train_preds)\n",
    "                self.logged_train_images_this_epoch = True\n",
    "            \n",
    "            self.train_imgs = None\n",
    "            self.train_preds = None\n",
    "            self.logged_train_images_this_epoch = False\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        lr = self.optimizers().param_groups[0]['lr']\n",
    "        if self.log_images:\n",
    "            self.logger.experiment.log({\"learning_rate\": lr}, commit=False)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.log_images:\n",
    "            if not self.logged_val_images_this_epoch and self.val_imgs is not None:\n",
    "                self._log_val_images(self.val_imgs, self.val_preds)\n",
    "                self.logged_val_images_this_epoch = True\n",
    "            \n",
    "            self.val_imgs = None\n",
    "            self.val_preds = None\n",
    "            self.logged_val_images_this_epoch = False\n",
    "\n",
    "            self._log_key_images()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def _log_val_images(self, imgs: torch.Tensor, preds: torch.Tensor):\n",
    "        grid = make_grid(imgs)\n",
    "        #grid_val = make_grid(preds).unsqueeze(1).float()\n",
    "        self.logger.experiment.log({\n",
    "            \"Validation Images\": [\n",
    "                wandb.Image(grid, caption=\"Original Images\"),\n",
    "                #wandb.Image(grid_val, caption=\"Features\")\n",
    "            ],\n",
    "        })\n",
    "\n",
    "    def _log_train_images(self, imgs: torch.Tensor, preds: torch.Tensor):\n",
    "        grid = make_grid(imgs)\n",
    "        #grid_val = make_grid(preds).unsqueeze(1).float()\n",
    "        self.logger.experiment.log({\n",
    "            \"Train Images\": [\n",
    "                wandb.Image(grid, caption=\"Original Images\"),\n",
    "                #wandb.Image(grid_val, caption=\"Features\")\n",
    "            ],\n",
    "        })\n",
    "\n",
    "    def _log_key_images(self):\n",
    "        attn, masks = self.attn, self.masks\n",
    "        attn_maps = make_grid(attn.reshape(-1, 14, 14)).unsqueeze(1)\n",
    "        masks = make_grid(masks.reshape(-1, 14, 14)).unsqueeze(1)\n",
    "      \n",
    "        self.logger.experiment.log({\n",
    "            \"Slot Attention Maps\": [\n",
    "                wandb.Image(attn_maps, caption=\"Attention Maps\"),\n",
    "            ],\n",
    "        })\n",
    "        self.logger.experiment.log({\n",
    "            \"Masks\": [\n",
    "                wandb.Image(masks, caption=\"Alpha Masks\"),\n",
    "            ],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_model.eval()\n",
    "oss = DINOSAUR(saved_model, saved_model2, num_slots=5, num_iterations=3, num_classes=4, slot_dim=256, task='recon',\n",
    "                                 learning_rate=4e-4, temperature=1, log_images=False, lr_warmup=True,\n",
    "                                 probabilistic_slots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|██████████| 96609/96609 [00:00<00:00, 1929495.28it/s]\n",
      "Loading Data: 100%|██████████| 5085/5085 [00:00<00:00, 1626728.38it/s]\n",
      "Loading Data: 100%|██████████| 25424/25424 [00:00<00:00, 1792111.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#data = JSRTDataModule(data_dir='./data/JSRT/', batch_size=32, augmentation=True)\n",
    "data = CheXpertDataModule(data_dir='/vol/biodata/data/chest_xray/CheXpert-v1.0/preproc_224x224/', batch_size=32, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/bitbucket/bc1623/project/uncertainty_env/lib/py ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                   | Type              | Params\n",
      "-------------------------------------------------------------\n",
      "0 | frozen_encoder         | VisionTransformer | 111 M \n",
      "1 | trainable_encoder      | VisionTransformer | 111 M \n",
      "2 | encoder_pos_embeddings | SoftPositionEmbed | 1.3 K \n",
      "3 | slot_attention         | SlotAttention     | 724 K \n",
      "4 | mlp_decoder            | Sequential        | 10.5 M\n",
      "5 | mlp                    | Sequential        | 262 K \n",
      "6 | decoder_pos_embeddings | SoftPositionEmbed | 1.3 K \n",
      "7 | embedding_norm         | LayerNorm         | 1.5 K \n",
      "8 | embedding_norm_decoder | LayerNorm         | 512   \n",
      "-------------------------------------------------------------\n",
      "122 M     Trainable params\n",
      "111 M     Non-trainable params\n",
      "233 M     Total params\n",
      "935.964   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8df43b684fa4abfb523b9cca4f3809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefa16b4b76f45d0b2a0536ab8c96adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pathlib import Path\n",
    "# wandb_logger = WandbLogger(save_dir='./runs/lightning_logs/dinosaur_recons/', project='dinosaur_recons')\n",
    "# output_dir = Path(f\"dinosaur_recons/run_{wandb_logger.experiment.id}\")  # type: ignore\n",
    "# print(\"Saving to\" + str(output_dir.absolute()))\n",
    "\n",
    "trainer = Trainer(\n",
    "    #max_epochs=5000,\n",
    "    max_steps=500000,\n",
    "    precision='16-mixed',\n",
    "    accelerator='auto',\n",
    "    devices=[0],\n",
    "    #strategy='ddp_notebook',\n",
    "    # log_every_n_steps=250,\n",
    "    check_val_every_n_epoch=50,\n",
    "    # #save_top_k=1,\n",
    "    #logger=wandb_logger,\n",
    "    # callbacks=[ModelCheckpoint(monitor=\"val_loss\", mode='min'), TQDMProgressBar(refresh_rate=100)],\n",
    ")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainer.fit(model=oss, datamodule=data)\n",
    "\n",
    "# trainer.validate(model=oss, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "# trainer.test(model=oss, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 0\n",
    "batch = next(iter(data.test_dataloader()))\n",
    "# vertical flip batch\n",
    "# batch['image'] = torch.flip(batch['image'], [2])\n",
    "# batch['labelmap'] = torch.flip(batch['labelmap'], [2])\n",
    "\n",
    "batch['image'] = batch['image'][:2]\n",
    "batch['labelmap'] = batch['labelmap'][:2]\n",
    "# move to gpu\n",
    "# batch = {k: v.to(cuda_device) for k, v in batch.items()}\n",
    "# oss.to(cuda_device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss, dsc, probs, preds, _ = oss.process_batch(batch, 1)\n",
    "image = batch['image'][image_num].squeeze()\n",
    "labelmap = batch['labelmap'][image_num].squeeze()\n",
    "probmap = torch.max(probs.cpu(), dim=1, keepdim=True)[0].squeeze().detach().numpy()\n",
    "predmap = preds[image_num].squeeze()\n",
    "\n",
    "f, ax = plt.subplots(1,4, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(image, cmap=matplotlib.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('image')\n",
    "\n",
    "ax[1].imshow(labelmap, cmap=matplotlib.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('labelmap')\n",
    "\n",
    "ax[2].imshow(predmap, cmap=matplotlib.cm.gray)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('prediction')\n",
    "\n",
    "ax[3].imshow(probmap[image_num, ...], cmap='plasma')\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('probability map')\n",
    "\n",
    "image_num += 1\n",
    "image = batch['image'][image_num].squeeze()\n",
    "labelmap = batch['labelmap'][image_num].squeeze()\n",
    "probmap = torch.max(probs.cpu(), dim=1, keepdim=True)[0].squeeze().detach().numpy()\n",
    "predmap = preds[image_num].squeeze()\n",
    "\n",
    "f, ax = plt.subplots(1,4, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(image, cmap=matplotlib.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('image')\n",
    "\n",
    "ax[1].imshow(labelmap, cmap=matplotlib.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('labelmap')\n",
    "\n",
    "ax[2].imshow(predmap, cmap=matplotlib.cm.gray)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('prediction')\n",
    "\n",
    "ax[3].imshow(probmap[image_num, ...], cmap='plasma')\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('probability map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot attention matrix\n",
    "image_num = 0\n",
    "attn = oss.attn[image_num].cpu().detach().numpy()   \n",
    "# slot 0\n",
    "# slot_0_attn = attn[0, :]\n",
    "# slot_0_attn = slot_0_attn.reshape(14, 14)\n",
    "\n",
    "f, ax = plt.subplots(1, attn.shape[0], figsize=(15, 15))\n",
    "\n",
    "for slot in range(attn.shape[0]):\n",
    "    slot_attn = attn[slot, :]\n",
    "    slot_attn = slot_attn.reshape(14, 14)\n",
    "    ax[slot].imshow(slot_attn, cmap=matplotlib.cm.gray)\n",
    "    ax[slot].axis('off')\n",
    "    ax[slot].set_title(f'slot {slot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate entropy of predictions\n",
    "image_num = 0\n",
    "trials = 5\n",
    "batch = next(iter(data.test_dataloader()))\n",
    "\n",
    "list_entropy = []\n",
    "#all_preds = torch.empty((batch['image'].shape[0], 224, 224), dtype=torch.long)\n",
    "oss.to(cuda_device)\n",
    "batch = {k: v.to(cuda_device) for k, v in batch.items()}\n",
    "for _ in range(trials):\n",
    "    with torch.no_grad():\n",
    "        loss, dsc, probs, preds, _ = oss.process_batch(batch)\n",
    "        list_entropy.append(preds)\n",
    "\n",
    "all_preds = torch.stack(list_entropy, dim=1)\n",
    "oss.to('cpu')\n",
    "del batch\n",
    "print(all_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_entropy(predictions):\n",
    "    \"\"\"\n",
    "    Calculate entropy of class predictions for each pixel.\n",
    "    \n",
    "    Args:\n",
    "    predictions: Tensor of shape (N, H, W) where N is the number of predictions,\n",
    "                 H and W are height and width. Values are class indices.\n",
    "    \n",
    "    Returns:\n",
    "    entropy: Tensor of shape (H, W) containing entropy for each pixel\n",
    "    \"\"\"\n",
    "    N, H, W = predictions.shape\n",
    "    num_classes = predictions.max().item() + 1  # Assuming class indices start from 0\n",
    "    \n",
    "    # Create one-hot encoding\n",
    "    one_hot = torch.zeros(N, num_classes, H, W, device=predictions.device)\n",
    "    one_hot.scatter_(1, predictions.unsqueeze(1), 1)\n",
    "    \n",
    "    # Sum over the N dimension to get class counts\n",
    "    class_counts = one_hot.sum(dim=0)  # Shape: (num_classes, H, W)\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    probabilities = class_counts / N\n",
    "    \n",
    "    # Add a small epsilon to avoid log(0)\n",
    "    epsilon = 1e-7\n",
    "    probabilities = torch.clamp(probabilities, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = -torch.sum(probabilities * torch.log2(probabilities), dim=0)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'stacked_predictions' is your tensor of shape (N, H, W)\n",
    "image_num = 7\n",
    "pixel_entropy = calculate_class_entropy(all_preds[image_num, ...]).cpu()\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(pixel_entropy, cmap='plasma')\n",
    "ax.axis('off')\n",
    "ax.set_title('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertainty_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
