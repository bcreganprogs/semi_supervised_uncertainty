{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py:927\u001b[0m, in \u001b[0;36mPathDistribution.read_text\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[1;32m    926\u001b[0m ):\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1134\u001b[0m, in \u001b[0;36mPath.read_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1133\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/xxhash-3.4.1.dist-info/entry_points.txt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, seed_everything\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/matplotlib/__init__.py:1270\u001b[0m\n\u001b[1;32m   1266\u001b[0m     rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend_fallback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPLBACKEND\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1270\u001b[0m     \u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPLBACKEND\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_backend\u001b[39m():\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;124;03m    Return the name of the current backend.\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m    matplotlib.use\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/matplotlib/__init__.py:736\u001b[0m, in \u001b[0;36mRcParams.__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     cval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/matplotlib/rcsetup.py:273\u001b[0m, in \u001b[0;36mvalidate_backend\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_backend\u001b[39m(s):\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m _auto_backend_sentinel \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mbackend_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_valid_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/matplotlib/backends/registry.py:243\u001b[0m, in \u001b[0;36mBackendRegistry.is_valid_backend\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Only load entry points if really need to and not already done so.\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_entry_points_loaded\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_to_gui_framework:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/matplotlib/backends/registry.py:113\u001b[0m, in \u001b[0;36mBackendRegistry._ensure_entry_points_loaded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_entry_points_loaded\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# Load entry points, if they have not already been loaded.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_entry_points:\n\u001b[0;32m--> 113\u001b[0m         entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_entry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_store_entry_points(entries)\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_entry_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/matplotlib/backends/registry.py:137\u001b[0m, in \u001b[0;36mBackendRegistry._read_entry_points\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m group \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib.backend\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m--> 137\u001b[0m     entry_points \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     entry_points \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mentry_points()\u001b[38;5;241m.\u001b[39mget(group, ())\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py:1021\u001b[0m, in \u001b[0;36mentry_points\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m unique \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(unique_everseen, key\u001b[38;5;241m=\u001b[39mnorm_name)\n\u001b[1;32m   1018\u001b[0m eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   1019\u001b[0m     dist\u001b[38;5;241m.\u001b[39mentry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m unique(distributions())\n\u001b[1;32m   1020\u001b[0m )\n\u001b[0;32m-> 1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSelectableGroups\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py:459\u001b[0m, in \u001b[0;36mSelectableGroups.load\u001b[0;34m(cls, eps)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, eps):\n\u001b[1;32m    458\u001b[0m     by_group \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m     ordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mgroupby(ordered, by_group)\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m((group, EntryPoints(eps)) \u001b[38;5;28;01mfor\u001b[39;00m group, eps \u001b[38;5;129;01min\u001b[39;00m grouped)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py:1019\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1016\u001b[0m norm_name \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_normalized_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1017\u001b[0m unique \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(unique_everseen, key\u001b[38;5;241m=\u001b[39mnorm_name)\n\u001b[1;32m   1018\u001b[0m eps \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 1019\u001b[0m     \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m unique(distributions())\n\u001b[1;32m   1020\u001b[0m )\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SelectableGroups\u001b[38;5;241m.\u001b[39mload(eps)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py:631\u001b[0m, in \u001b[0;36mDistribution.entry_points\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints\u001b[38;5;241m.\u001b[39m_from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentry_points.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py:927\u001b[0m, in \u001b[0;36mPathDistribution.read_text\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[1;32m    921\u001b[0m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[1;32m    922\u001b[0m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[1;32m    926\u001b[0m     ):\n\u001b[0;32m--> 927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "\n",
    "from models.data import JSRTDataModule, CheXpertDataModule\n",
    "from models.mae import ViTAE\n",
    "from models.dinosaur import DINOSAUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = ViTAE.load_from_checkpoint('/vol/bitbucket/bc1623/project/semi_supervised_uncertainty/bash_scripts/lightning_logs/chestxray_mae/chestxray_mae/beznyxtr/checkpoints/epoch=495-step=93744.ckpt',\n",
    "    model_kwargs={\n",
    "        'img_size': 224,\n",
    "        'embed_dim': 768,\n",
    "        'in_chans': 1,\n",
    "        'num_heads': 12,\n",
    "        'depth': 12,\n",
    "        'decoder_embed_dim': 512,\n",
    "        'decoder_depth': 8,\n",
    "        'decoder_num_heads': 16,\n",
    "        'norm_layer': partial(nn.LayerNorm, eps=1e-6),\n",
    "        'mlp_ratio': 4.0,\n",
    "        'patch_size': 16,\n",
    "        'norm_pix_loss': False,\n",
    "        'mask_ratio': 0.00,\n",
    "        #'dropout': 0.00,\n",
    "    },\n",
    "    learning_rate=1e-4,\n",
    "    map_location=torch.device('cpu'),\n",
    "    )\n",
    "\n",
    "saved_model2 = ViTAE.load_from_checkpoint('/vol/bitbucket/bc1623/project/semi_supervised_uncertainty/bash_scripts/lightning_logs/chestxray_mae/chestxray_mae/beznyxtr/checkpoints/epoch=495-step=93744.ckpt',\n",
    "    model_kwargs={\n",
    "        'img_size': 224,\n",
    "        'embed_dim': 768,\n",
    "        'in_chans': 1,\n",
    "        'num_heads': 12,\n",
    "        'depth': 12,\n",
    "        'decoder_embed_dim': 512,\n",
    "        'decoder_depth': 8,\n",
    "        'decoder_num_heads': 16,\n",
    "        'norm_layer': partial(nn.LayerNorm, eps=1e-6),\n",
    "        'mlp_ratio': 4.0,\n",
    "        'patch_size': 16,\n",
    "        'norm_pix_loss': False,\n",
    "        'mask_ratio': 0.00,\n",
    "        #'dropout': 0.00,\n",
    "    },\n",
    "    learning_rate=1e-4,\n",
    "    map_location=torch.device('cpu'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchmetrics.functional import dice\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
    "from pytorch_lightning import LightningModule\n",
    "import wandb\n",
    "\n",
    "from utils.utils import SoftPositionEmbed, spatial_broadcast, unstack_and_split\n",
    "from models.slot_attention import ProbabalisticSlotAttention, FixedSlotAttention, SlotAttention\n",
    "from models.decoders import SlotSpecificDecoder, Decoder\n",
    "\n",
    "class DINOSAUR(LightningModule):\n",
    "    def __init__(self, frozen_encoder, trainable_encoder, num_slots, num_iterations, num_classes, slot_dim=128, task='recon', include_seg_loss=False, probabilistic_slots=True, \n",
    "                learning_rate=1e-3, hidden_decoder_dim=1024, temperature=1, lr_warmup=True, log_images=True):\n",
    "        super(DINOSAUR, self).__init__()\n",
    "\n",
    "        self.frozen_encoder = frozen_encoder.model\n",
    "        self.trainable_encoder = trainable_encoder.model\n",
    "        self.encoder_pos_embeddings = SoftPositionEmbed(slot_dim, (14, 14))\n",
    "        if probabilistic_slots:\n",
    "            self.slot_attention = ProbabalisticSlotAttention(num_slots=num_slots, dim=slot_dim, num_iterations=num_iterations, temperature=temperature)\n",
    "        else:\n",
    "            self.slot_attention = SlotAttention(num_slots, slot_dim, num_iterations, temperature=temperature)\n",
    "            #FixedSlotAttention(num_slots=num_slots, dim=slot_dim, num_iterations=num_iterations, temperature=temperature)  #SlotAttention(num_slots, 1024, num_iterations)\n",
    "        \n",
    "        # four-layer mlp\n",
    "        self.mlp_decoder = nn.Sequential(\n",
    "            nn.Linear(slot_dim, hidden_decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_decoder_dim, hidden_decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_decoder_dim, hidden_decoder_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_decoder_dim, 768 + 1) # extra one for alpha masks\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(768, slot_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(slot_dim, slot_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder_pos_embeddings = SoftPositionEmbed(slot_dim, (1, 196))\n",
    "        self.num_classes = num_classes\n",
    "        self.task = task\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_warmup = lr_warmup\n",
    "        self.embedding_norm = nn.LayerNorm(768)\n",
    "\n",
    "        self.include_seg_loss = include_seg_loss\n",
    "\n",
    "        self.attn = None\n",
    "        self.masks = None\n",
    "        self.recons = None\n",
    "        self.preds = None\n",
    "\n",
    "        for param in self.frozen_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "  \n",
    "        self.mlp_decoder.apply(self.init_weights)\n",
    "        self.mlp.apply(self.init_weights)\n",
    "        self.slot_attention.apply(self.init_weights)\n",
    "\n",
    "        self.test_predmaps = []\n",
    "        self.test_probmaps = []\n",
    "\n",
    "        # for logging\n",
    "        self.log_images = log_images\n",
    "        if log_images:\n",
    "            self.save_hyperparameters(ignore=['encoder'])\n",
    "\n",
    "        self.train_imgs = None\n",
    "        self.train_preds = None\n",
    "        self.val_imgs = None\n",
    "        self.val_preds = None\n",
    "        self.logged_train_images_this_epoch = False\n",
    "        self.logged_val_images_this_epoch = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        with torch.no_grad():\n",
    "            patch_embeddings_frozen, _, _ = self.frozen_encoder.forward_encoder(x, 0.0)\n",
    "            patch_embeddings_frozen = patch_embeddings_frozen[:, 1:, :]     # exclude cls token\n",
    "\n",
    "        # generate patch features from trainable encoder\n",
    "        patch_embeddings_train, _, _ = self.trainable_encoder.forward_encoder(x, 0.0)\n",
    "        patch_embeddings_train = patch_embeddings_train[:, 1:, :]           # exclude cls token\n",
    "\n",
    "        # intermediate mlp between encoder and slot attention\n",
    "        patch_embeddings_train = self.embedding_norm(patch_embeddings_train)\n",
    "        patch_embeddings_train = self.mlp(patch_embeddings_train)                       # shape (batch_size*num_patches, embed_dim)\n",
    "\n",
    "        # apply slot attention to trainable patch features\n",
    "        slots, slot_attn = self.slot_attention(patch_embeddings_train)            # slots: shape (batch_size, num_slots, slot_dim)\n",
    "    \n",
    "        # broadcast each slot to N x N grid (N=14 for 224x224 images)\n",
    "        x = spatial_broadcast(slots, (1, 196))                              # shape (batch_size*num_slots, width_init, height_init, slot_dim)\n",
    "\n",
    "        # decode each slot to a mask\n",
    "        x = self.decoder_pos_embeddings(x)\n",
    "\n",
    "        x = x.view(batch_size, slots.shape[1], 14*14, -1)\n",
    "\n",
    "        x = self.mlp_decoder(x).to(patch_embeddings_train.device)               # shape (batch_size, num_classes, H, W)\n",
    "\n",
    "        decoded = x[:, :, :, :-1]                                               # shape (batch_size, num_slots, num_patches, slot_dim)\n",
    "        masks = x[:, :, :, -1]                                                  # shape (batch_size, num_slots, num_patches)\n",
    "        masks = torch.softmax(masks, dim=1)                                     # softmax over \n",
    "        # log masks\n",
    "        self.masks = masks[0, ...]\n",
    "        masks = masks.unsqueeze(-1)                                             # shape (batch_size, num_slots, num_patches, slot_dim)\n",
    "        recons = torch.sum(decoded * masks, dim=1)\n",
    "\n",
    "        preds = torch.argmax(masks, dim=1)\n",
    "\n",
    "        return patch_embeddings_frozen, recons, masks, preds, slot_attn\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=1e-6)\n",
    "        if not self.lr_warmup:\n",
    "            return optimizer\n",
    "\n",
    "        scheduler = self.warmup_lr_scheduler(optimizer, 10000, 100000, 1e-6, self.learning_rate)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "             \"lr_scheduler\": {\n",
    "                 \"scheduler\": scheduler,\n",
    "            #     #\"monitor\": \"train_loss\",  # metric to monitor\n",
    "                 \"frequency\": 1,  \n",
    "                 \"interval\": \"step\",\n",
    "            #     #\"strict\": True,\n",
    "             },\n",
    "        }\n",
    "    \n",
    "    def warmup_lr_scheduler(self, optimizer, warmup_steps, decay_steps, start_lr, target_lr):\n",
    "        def lr_lambda(current_step):\n",
    "            if current_step < warmup_steps:\n",
    "                return float(current_step) / float(max(1, warmup_steps)) * (target_lr - start_lr) / target_lr + start_lr / target_lr\n",
    "            else:\n",
    "                return 0.5 ** ((current_step - warmup_steps) / decay_steps)\n",
    "        return LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    def process_batch(self, batch, batch_idx):\n",
    "        x, y = batch['image'], batch['labelmap']\n",
    "        # generate patch features from frozen encoder\n",
    "        targets, recons, masks, preds, attn = self(x)\n",
    "\n",
    "        # log masks and attn\n",
    "        self.attn = attn[0, ...]\n",
    "        self.recons = recons[0, ...]\n",
    "        self.preds = preds[0, ...]\n",
    "\n",
    "        # calculate loss\n",
    "        loss = torch.cdist(targets, recons, p=2).mean()\n",
    "        dsc = 1#dice(preds, y.squeeze(), average='macro', num_classes=self.num_classes, ignore_index=0)\n",
    "        \n",
    "        return loss, dsc, preds, x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, dsc, preds, imgs = self.process_batch(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_dice\", dsc, prog_bar=True)\n",
    "\n",
    "        if self.train_imgs is None:\n",
    "            self.train_imgs = imgs[:5].cpu()\n",
    "            self.train_preds = preds[:5].cpu()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, dsc, preds, imgs = self.process_batch(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_dice\", dsc, prog_bar=True, sync_dist=True)\n",
    "\n",
    "        if self.val_imgs is None:\n",
    "            self.val_imgs = imgs[:5].cpu()\n",
    "            self.val_preds = preds[:5].cpu()\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.test_probmaps = []\n",
    "        self.test_predmaps = []\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, dsc, probs, preds = self.process_batch(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_dice\", dsc)\n",
    "        self.test_probmaps.append(probs)\n",
    "        self.test_predmaps.append(preds)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.log_images:\n",
    "            if not self.logged_train_images_this_epoch and self.train_imgs is not None:\n",
    "                self._log_train_images(self.train_imgs, self.train_preds)\n",
    "                self.logged_train_images_this_epoch = True\n",
    "            \n",
    "            self.train_imgs = None\n",
    "            self.train_preds = None\n",
    "            self.logged_train_images_this_epoch = False\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        lr = self.optimizers().param_groups[0]['lr']\n",
    "        self.logger.experiment.log({\"learning_rate\": lr}, commit=False)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.log_images:\n",
    "            if not self.logged_val_images_this_epoch and self.val_imgs is not None:\n",
    "                self._log_val_images(self.val_imgs, self.val_preds)\n",
    "                self.logged_val_images_this_epoch = True\n",
    "            \n",
    "            self.val_imgs = None\n",
    "            self.val_preds = None\n",
    "            self.logged_val_images_this_epoch = False\n",
    "\n",
    "            self._log_key_images()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def _log_val_images(self, imgs: torch.Tensor, preds: torch.Tensor):\n",
    "        grid = make_grid(imgs)\n",
    "        grid_val = make_grid(preds).unsqueeze(1).float()\n",
    "        self.logger.experiment.log({\n",
    "            \"Validation Images\": [\n",
    "                wandb.Image(grid, caption=\"Original Images\"),\n",
    "                wandb.Image(grid_val, caption=\"Masked and Reconstructed Images\")\n",
    "            ],\n",
    "        })\n",
    "\n",
    "    def _log_train_images(self, imgs: torch.Tensor, preds: torch.Tensor):\n",
    "        grid = make_grid(imgs)\n",
    "        grid_val = make_grid(preds).unsqueeze(1).float()\n",
    "        self.logger.experiment.log({\n",
    "            \"Train Images\": [\n",
    "                wandb.Image(grid, caption=\"Original Images\"),\n",
    "                wandb.Image(grid_val, caption=\"Features\")\n",
    "            ],\n",
    "        })\n",
    "\n",
    "    def _log_key_images(self):\n",
    "        attn, masks = self.attn, self.masks\n",
    "        attn_maps = make_grid(attn.reshape(-1, 14, 14)).unsqueeze(1)\n",
    "        masks = make_grid(masks.reshape(-1, 1, 14, 14))\n",
    "      \n",
    "        self.logger.experiment.log({\n",
    "            \"Slot Attention Maps\": [\n",
    "                wandb.Image(attn_maps, caption=\"Attention Maps\"),\n",
    "            ],\n",
    "        })\n",
    "        self.logger.experiment.log({\n",
    "            \"Masks\": [\n",
    "                wandb.Image(masks, caption=\"Alpha Masks\"),\n",
    "            ],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_model.eval()\n",
    "oss = DINOSAUR(saved_model, saved_model2, num_slots=8, num_iterations=3, num_classes=4, slot_dim=256, task='recon',\n",
    "                                 learning_rate=4e-4, temperature=1, log_images=True, lr_warmup=True,\n",
    "                                 probabilistic_slots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = JSRTDataModule(data_dir='./data/JSRT/', batch_size=32, augmentation=True)\n",
    "#data = CheXpertDataModule(data_dir='/vol/biodata/data/chest_xray/CheXpert-v1.0/preproc_224x224/', batch_size=32, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pathlib import Path\n",
    "wandb_logger = WandbLogger(save_dir='./runs/lightning_logs/dinosaur_recons/', project='dinosaur_recons')\n",
    "output_dir = Path(f\"dinosaur_recons/run_{wandb_logger.experiment.id}\")  # type: ignore\n",
    "print(\"Saving to\" + str(output_dir.absolute()))\n",
    "\n",
    "trainer = Trainer(\n",
    "    #max_epochs=5000,\n",
    "    max_steps=500000,\n",
    "    precision='16-mixed',\n",
    "    accelerator='auto',\n",
    "    devices=[0],\n",
    "    #strategy='ddp_notebook',\n",
    "    # log_every_n_steps=250,\n",
    "    check_val_every_n_epoch=50,\n",
    "    # #save_top_k=1,\n",
    "    logger=wandb_logger,\n",
    "    # callbacks=[ModelCheckpoint(monitor=\"val_loss\", mode='min'), TQDMProgressBar(refresh_rate=100)],\n",
    ")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainer.fit(model=oss, datamodule=data)\n",
    "\n",
    "# trainer.validate(model=oss, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "# trainer.test(model=oss, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 0\n",
    "batch = next(iter(data.test_dataloader()))\n",
    "# vertical flip batch\n",
    "# batch['image'] = torch.flip(batch['image'], [2])\n",
    "# batch['labelmap'] = torch.flip(batch['labelmap'], [2])\n",
    "\n",
    "batch['image'] = batch['image'][:2]\n",
    "batch['labelmap'] = batch['labelmap'][:2]\n",
    "# move to gpu\n",
    "# batch = {k: v.to(cuda_device) for k, v in batch.items()}\n",
    "# oss.to(cuda_device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss, dsc, probs, preds, _ = oss.process_batch(batch, 1)\n",
    "image = batch['image'][image_num].squeeze()\n",
    "labelmap = batch['labelmap'][image_num].squeeze()\n",
    "probmap = torch.max(probs.cpu(), dim=1, keepdim=True)[0].squeeze().detach().numpy()\n",
    "predmap = preds[image_num].squeeze()\n",
    "\n",
    "f, ax = plt.subplots(1,4, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(image, cmap=matplotlib.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('image')\n",
    "\n",
    "ax[1].imshow(labelmap, cmap=matplotlib.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('labelmap')\n",
    "\n",
    "ax[2].imshow(predmap, cmap=matplotlib.cm.gray)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('prediction')\n",
    "\n",
    "ax[3].imshow(probmap[image_num, ...], cmap='plasma')\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('probability map')\n",
    "\n",
    "image_num += 1\n",
    "image = batch['image'][image_num].squeeze()\n",
    "labelmap = batch['labelmap'][image_num].squeeze()\n",
    "probmap = torch.max(probs.cpu(), dim=1, keepdim=True)[0].squeeze().detach().numpy()\n",
    "predmap = preds[image_num].squeeze()\n",
    "\n",
    "f, ax = plt.subplots(1,4, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(image, cmap=matplotlib.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('image')\n",
    "\n",
    "ax[1].imshow(labelmap, cmap=matplotlib.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('labelmap')\n",
    "\n",
    "ax[2].imshow(predmap, cmap=matplotlib.cm.gray)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('prediction')\n",
    "\n",
    "ax[3].imshow(probmap[image_num, ...], cmap='plasma')\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('probability map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot attention matrix\n",
    "image_num = 0\n",
    "attn = oss.attn[image_num].cpu().detach().numpy()   \n",
    "# slot 0\n",
    "# slot_0_attn = attn[0, :]\n",
    "# slot_0_attn = slot_0_attn.reshape(14, 14)\n",
    "\n",
    "f, ax = plt.subplots(1, attn.shape[0], figsize=(15, 15))\n",
    "\n",
    "for slot in range(attn.shape[0]):\n",
    "    slot_attn = attn[slot, :]\n",
    "    slot_attn = slot_attn.reshape(14, 14)\n",
    "    ax[slot].imshow(slot_attn, cmap=matplotlib.cm.gray)\n",
    "    ax[slot].axis('off')\n",
    "    ax[slot].set_title(f'slot {slot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate entropy of predictions\n",
    "image_num = 0\n",
    "trials = 5\n",
    "batch = next(iter(data.test_dataloader()))\n",
    "\n",
    "list_entropy = []\n",
    "#all_preds = torch.empty((batch['image'].shape[0], 224, 224), dtype=torch.long)\n",
    "oss.to(cuda_device)\n",
    "batch = {k: v.to(cuda_device) for k, v in batch.items()}\n",
    "for _ in range(trials):\n",
    "    with torch.no_grad():\n",
    "        loss, dsc, probs, preds, _ = oss.process_batch(batch)\n",
    "        list_entropy.append(preds)\n",
    "\n",
    "all_preds = torch.stack(list_entropy, dim=1)\n",
    "oss.to('cpu')\n",
    "del batch\n",
    "print(all_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_entropy(predictions):\n",
    "    \"\"\"\n",
    "    Calculate entropy of class predictions for each pixel.\n",
    "    \n",
    "    Args:\n",
    "    predictions: Tensor of shape (N, H, W) where N is the number of predictions,\n",
    "                 H and W are height and width. Values are class indices.\n",
    "    \n",
    "    Returns:\n",
    "    entropy: Tensor of shape (H, W) containing entropy for each pixel\n",
    "    \"\"\"\n",
    "    N, H, W = predictions.shape\n",
    "    num_classes = predictions.max().item() + 1  # Assuming class indices start from 0\n",
    "    \n",
    "    # Create one-hot encoding\n",
    "    one_hot = torch.zeros(N, num_classes, H, W, device=predictions.device)\n",
    "    one_hot.scatter_(1, predictions.unsqueeze(1), 1)\n",
    "    \n",
    "    # Sum over the N dimension to get class counts\n",
    "    class_counts = one_hot.sum(dim=0)  # Shape: (num_classes, H, W)\n",
    "    \n",
    "    # Calculate probabilities\n",
    "    probabilities = class_counts / N\n",
    "    \n",
    "    # Add a small epsilon to avoid log(0)\n",
    "    epsilon = 1e-7\n",
    "    probabilities = torch.clamp(probabilities, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = -torch.sum(probabilities * torch.log2(probabilities), dim=0)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'stacked_predictions' is your tensor of shape (N, H, W)\n",
    "image_num = 7\n",
    "pixel_entropy = calculate_class_entropy(all_preds[image_num, ...]).cpu()\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "ax.imshow(pixel_entropy, cmap='plasma')\n",
    "ax.axis('off')\n",
    "ax.set_title('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertainty_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
