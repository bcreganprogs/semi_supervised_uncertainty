{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.data import CURVASDataModule, SynthCardDataModule\n",
    "from models.encoders import DinoViT_16\n",
    "from models.segmentation import ObjectSpecificSegmentation\n",
    "from models.uncertainty_measures import make\n",
    "from models.curvas_metrics import consensus_dice_score\n",
    "from monai.networks import one_hot\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|██████████| 3800/3800 [00:00<00:00, 1838121.92it/s]\n",
      "Loading Data: 100%|██████████| 200/200 [00:00<00:00, 1530767.88it/s]\n",
      "Loading Data: 100%|██████████| 1000/1000 [00:00<00:00, 1619422.39it/s]\n"
     ]
    }
   ],
   "source": [
    "data = SynthCardDataModule(batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalised_uncertainties(model, batch, trials=500):\n",
    "\n",
    "    model.slot_attention.probabilistic_sample = True\n",
    "    model.to('cuda')\n",
    "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "    list_entropy = []\n",
    "    for _ in range(trials):\n",
    "        with torch.no_grad():\n",
    "            _, _, _, preds, _, _, _, _ = model.process_batch(batch, 1)\n",
    "\n",
    "            new_preds = one_hot(preds, num_classes=4)[:, 1:].permute(1, 0, 2, 3)\n",
    "\n",
    "            list_entropy.append(new_preds)\n",
    "\n",
    "    all_preds = torch.stack(list_entropy, dim=0).float()\n",
    "\n",
    "    vars = torch.var(all_preds, dim=0)\n",
    "\n",
    "    # normalize variance to 0, 1\n",
    "    vars = (vars - vars.min()) / (vars.max() - vars.min())\n",
    "    vars *= 100.0 \n",
    "\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /homes/bc1623/.cache/torch/hub/facebookresearch_dino_main\n",
      "/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Found keys that are in the model state dict but not in the checkpoint: ['decoder.recon_projs.0.0.weight', 'decoder.recon_projs.0.0.bias', 'decoder.recon_projs.0.2.weight', 'decoder.recon_projs.0.2.bias', 'decoder.recon_projs.0.4.weight', 'decoder.recon_projs.0.4.bias', 'decoder.recon_projs.1.0.weight', 'decoder.recon_projs.1.0.bias', 'decoder.recon_projs.1.2.weight', 'decoder.recon_projs.1.2.bias', 'decoder.recon_projs.1.4.weight', 'decoder.recon_projs.1.4.bias', 'decoder.recon_projs.2.0.weight', 'decoder.recon_projs.2.0.bias', 'decoder.recon_projs.2.2.weight', 'decoder.recon_projs.2.2.bias', 'decoder.recon_projs.2.4.weight', 'decoder.recon_projs.2.4.bias', 'decoder.recon_projs.3.0.weight', 'decoder.recon_projs.3.0.bias', 'decoder.recon_projs.3.2.weight', 'decoder.recon_projs.3.2.bias', 'decoder.recon_projs.3.4.weight', 'decoder.recon_projs.3.4.bias', 'decoder.recon_projs.4.0.weight', 'decoder.recon_projs.4.0.bias', 'decoder.recon_projs.4.2.weight', 'decoder.recon_projs.4.2.bias', 'decoder.recon_projs.4.4.weight', 'decoder.recon_projs.4.4.bias', 'decoder.recon_projs.5.0.weight', 'decoder.recon_projs.5.0.bias', 'decoder.recon_projs.5.2.weight', 'decoder.recon_projs.5.2.bias', 'decoder.recon_projs.5.4.weight', 'decoder.recon_projs.5.4.bias', 'decoder.recon_projs.6.0.weight', 'decoder.recon_projs.6.0.bias', 'decoder.recon_projs.6.2.weight', 'decoder.recon_projs.6.2.bias', 'decoder.recon_projs.6.4.weight', 'decoder.recon_projs.6.4.bias', 'decoder.recon_projs.7.0.weight', 'decoder.recon_projs.7.0.bias', 'decoder.recon_projs.7.2.weight', 'decoder.recon_projs.7.2.bias', 'decoder.recon_projs.7.4.weight', 'decoder.recon_projs.7.4.bias', 'decoder.mask_projs.0.0.weight', 'decoder.mask_projs.0.0.bias', 'decoder.mask_projs.0.2.weight', 'decoder.mask_projs.0.2.bias', 'decoder.mask_projs.0.4.weight', 'decoder.mask_projs.0.4.bias', 'decoder.mask_projs.1.0.weight', 'decoder.mask_projs.1.0.bias', 'decoder.mask_projs.1.2.weight', 'decoder.mask_projs.1.2.bias', 'decoder.mask_projs.1.4.weight', 'decoder.mask_projs.1.4.bias', 'decoder.mask_projs.2.0.weight', 'decoder.mask_projs.2.0.bias', 'decoder.mask_projs.2.2.weight', 'decoder.mask_projs.2.2.bias', 'decoder.mask_projs.2.4.weight', 'decoder.mask_projs.2.4.bias', 'decoder.mask_projs.3.0.weight', 'decoder.mask_projs.3.0.bias', 'decoder.mask_projs.3.2.weight', 'decoder.mask_projs.3.2.bias', 'decoder.mask_projs.3.4.weight', 'decoder.mask_projs.3.4.bias', 'decoder.mask_projs.4.0.weight', 'decoder.mask_projs.4.0.bias', 'decoder.mask_projs.4.2.weight', 'decoder.mask_projs.4.2.bias', 'decoder.mask_projs.4.4.weight', 'decoder.mask_projs.4.4.bias', 'decoder.mask_projs.5.0.weight', 'decoder.mask_projs.5.0.bias', 'decoder.mask_projs.5.2.weight', 'decoder.mask_projs.5.2.bias', 'decoder.mask_projs.5.4.weight', 'decoder.mask_projs.5.4.bias', 'decoder.mask_projs.6.0.weight', 'decoder.mask_projs.6.0.bias', 'decoder.mask_projs.6.2.weight', 'decoder.mask_projs.6.2.bias', 'decoder.mask_projs.6.4.weight', 'decoder.mask_projs.6.4.bias', 'decoder.mask_projs.7.0.weight', 'decoder.mask_projs.7.0.bias', 'decoder.mask_projs.7.2.weight', 'decoder.mask_projs.7.2.bias', 'decoder.mask_projs.7.4.weight', 'decoder.mask_projs.7.4.bias']\n",
      "/vol/bitbucket/bc1623/project/uncertainty_env/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['decoder.recons_block.self_attn_mask', 'decoder.recons_block.self_attn_layer_norm.weight', 'decoder.recons_block.self_attn_layer_norm.bias', 'decoder.recons_block.self_attn.proj_q.weight', 'decoder.recons_block.self_attn.proj_k.weight', 'decoder.recons_block.self_attn.proj_v.weight', 'decoder.recons_block.self_attn.proj_o.weight', 'decoder.recons_block.encoder_decoder_attn_layer_norm.weight', 'decoder.recons_block.encoder_decoder_attn_layer_norm.bias', 'decoder.recons_block.encoder_decoder_attn.proj_q.weight', 'decoder.recons_block.encoder_decoder_attn.proj_k.weight', 'decoder.recons_block.encoder_decoder_attn.proj_v.weight', 'decoder.recons_block.encoder_decoder_attn.proj_o.weight', 'decoder.recons_block.ffn_layer_norm.weight', 'decoder.recons_block.ffn_layer_norm.bias', 'decoder.recons_block.ffn.0.weight', 'decoder.recons_block.ffn.0.bias', 'decoder.recons_block.ffn.2.weight', 'decoder.recons_block.ffn.2.bias', 'decoder.masks_block.self_attn_mask', 'decoder.masks_block.self_attn_layer_norm.weight', 'decoder.masks_block.self_attn_layer_norm.bias', 'decoder.masks_block.self_attn.proj_q.weight', 'decoder.masks_block.self_attn.proj_k.weight', 'decoder.masks_block.self_attn.proj_v.weight', 'decoder.masks_block.self_attn.proj_o.weight', 'decoder.masks_block.encoder_decoder_attn_layer_norm.weight', 'decoder.masks_block.encoder_decoder_attn_layer_norm.bias', 'decoder.masks_block.encoder_decoder_attn.proj_q.weight', 'decoder.masks_block.encoder_decoder_attn.proj_k.weight', 'decoder.masks_block.encoder_decoder_attn.proj_v.weight', 'decoder.masks_block.encoder_decoder_attn.proj_o.weight', 'decoder.masks_block.ffn_layer_norm.weight', 'decoder.masks_block.ffn_layer_norm.bias', 'decoder.masks_block.ffn.0.weight', 'decoder.masks_block.ffn.0.bias', 'decoder.masks_block.ffn.2.weight', 'decoder.masks_block.ffn.2.bias', 'decoder.layer_norm_masks.weight', 'decoder.layer_norm_masks.bias', 'decoder.recon_projs.0.weight', 'decoder.recon_projs.0.bias', 'decoder.recon_projs.1.weight', 'decoder.recon_projs.1.bias', 'decoder.recon_projs.2.weight', 'decoder.recon_projs.2.bias', 'decoder.recon_projs.3.weight', 'decoder.recon_projs.3.bias', 'decoder.recon_projs.4.weight', 'decoder.recon_projs.4.bias', 'decoder.recon_projs.5.weight', 'decoder.recon_projs.5.bias', 'decoder.recon_projs.6.weight', 'decoder.recon_projs.6.bias', 'decoder.recon_projs.7.weight', 'decoder.recon_projs.7.bias', 'decoder.mask_projs.0.weight', 'decoder.mask_projs.0.bias', 'decoder.mask_projs.1.weight', 'decoder.mask_projs.1.bias', 'decoder.mask_projs.2.weight', 'decoder.mask_projs.2.bias', 'decoder.mask_projs.3.weight', 'decoder.mask_projs.3.bias', 'decoder.mask_projs.4.weight', 'decoder.mask_projs.4.bias', 'decoder.mask_projs.5.weight', 'decoder.mask_projs.5.bias', 'decoder.mask_projs.6.weight', 'decoder.mask_projs.6.bias', 'decoder.mask_projs.7.weight', 'decoder.mask_projs.7.bias']\n"
     ]
    }
   ],
   "source": [
    "encoder = DinoViT_16()\n",
    "oss = ObjectSpecificSegmentation.load_from_checkpoint('/vol/bitbucket/bc1623/project/semi_supervised_uncertainty/bash_scripts/runs/lightning_logs/abd_seg/abd_seg/1_ar_t/checkpoints/epoch=429-step=119110.ckpt',\n",
    "                                encoder=encoder, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 4, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(data.test_dataloader()))\n",
    "\n",
    "ground_truth = batch['labelmap']\n",
    "\n",
    "batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    oss.slot_attention.probabilistic_sample = False\n",
    "    loss, dsc, probs, preds, _, _, _, attn = oss.process_batch(batch, 1)\n",
    "\n",
    "print(probs.shape)\n",
    "predictions = preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 512, 512])\n",
      "torch.Size([3, 25, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(new_preds.shape)\n",
    "new_preds = one_hot(preds, num_classes=4)[:, 1:].permute(1, 0, 2, 3)\n",
    "print(new_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 25, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "vars = get_normalised_uncertainties(oss, batch, trials=50)\n",
    "print(vars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1, 512, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (25,512,512) (3,512,512) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# groundtruth: numpy stack list containing the three ground truths [gt1, gt2, gt3]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#                 each gt has the following values: 1: pancreas, 2: kidney, 3: liver\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#                 (3, slices, X, Y)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# bin_pred: binarized prediction matrix containing values: {0,1,2,3}\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# prob_pred: probability prediction matrix, shape: (3, slices, X, Y), the three being\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#             a probability matrix per each class\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m dice, confidence \u001b[38;5;241m=\u001b[39m \u001b[43mconsensus_dice_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/bc1623/project/semi_supervised_uncertainty/models/curvas_metrics.py:102\u001b[0m, in \u001b[0;36mconsensus_dice_score\u001b[0;34m(groundtruth, bin_pred, prob_pred)\u001b[0m\n\u001b[1;32m     98\u001b[0m confidence \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m organ_val, organ_name \u001b[38;5;129;01min\u001b[39;00m organs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Apply the dissensus mask to exclude non-consensus areas\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     filtered_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[43morgan_val\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdissensus\u001b[49m\u001b[43m[\u001b[49m\u001b[43morgan_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     filtered_groundtruth \u001b[38;5;241m=\u001b[39m consensus[organ_name] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dissensus[organ_name])\n\u001b[1;32m    105\u001b[0m     predictions[organ_name] \u001b[38;5;241m=\u001b[39m filtered_prediction\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (25,512,512) (3,512,512) "
     ]
    }
   ],
   "source": [
    "# groundtruth: numpy stack list containing the three ground truths [gt1, gt2, gt3]\n",
    "#                 each gt has the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "#                 (3, slices, X, Y)\n",
    "# bin_pred: binarized prediction matrix containing values: {0,1,2,3}\n",
    "# prob_pred: probability prediction matrix, shape: (3, slices, X, Y), the three being\n",
    "#             a probability matrix per each class\n",
    "\n",
    "dice, confidence = consensus_dice_score(ground_truth.cpu().numpy(), predictions.squeeze(1), vars.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ground_truth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m25.0\u001b[39m, \u001b[38;5;241m50.0\u001b[39m, \u001b[38;5;241m75.0\u001b[39m, \u001b[38;5;241m100.0\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[image_num]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# segmentation and uncertainty maps from model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ground_truth'"
     ]
    }
   ],
   "source": [
    "batch = next(iter(data.test_dataloader()))\n",
    "\n",
    "thresholds = np.array([25.0, 50.0, 75.0, 100.0])\n",
    "for image_num in range(25):\n",
    "    ground_truth = batch['ground_truth'][image_num].numpy()\n",
    "\n",
    "    # segmentation and uncertainty maps from model\n",
    "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        loss, dsc, probs, preds, _, _, _, attn = oss.process_batch(batch, 1)\n",
    "    segmentation = preds[image_num].cpu().numpy()\n",
    "    uncertainties = get_normalised_uncertainties(oss, batch, trials=500).cpu().numpy()[image_num]\n",
    "    mask = np.ones_like(ground_truth)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9501359927470535,\n",
       "  0.9454436450839329,\n",
       "  0.9404407385348421,\n",
       "  0.9340788699234844],\n",
       " [0.009451796, 0.006301197, 0.0050409576, 0.0],\n",
       " [0.004048583, 0.0010293007, 0.0006862005, 0.0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def calculate_metrics(ground_truth, segmentation, uncertainties, mask, thresholds, object=3):\n",
    "    # Define Uncertainty Threshold points\n",
    "    _UNC_POINTs = np.arange(0.0, 100.0 + 1e-6, 100.0 / len(thresholds)).tolist()\n",
    "    _UNC_POINTs.reverse()\n",
    "    make(ground_truth==object, segmentation==object, uncertainties, mask, thresholds)\n",
    "\n",
    "    auc_dice = auc(_UNC_POINTs, make.dice)\n",
    "    auc_ftp = auc(_UNC_POINTs, make.ftp)\n",
    "    auc_ftn = auc(_UNC_POINTs, make.ftn)\n",
    "\n",
    "    metric = (auc_dice + (1 - auc_ftp) + (1 - auc_ftn)) / 3\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertainty_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
